# 시행착오

1. MMSE 양자화로 인한 워크스테이션 강제 재부팅
   - quantized_algoritm = "mmse" 사용시 CPU 부하 급증, dataset 수를 300장 이하로 줄여도 PC가 반복적으로 리부트
   - taskset, OMP_NUM_THREADS=1, CPU cap 등 모든 제한을 걸어도 동일
   - 결론: 현재 워크스테이션 환경에서는 MMSE 실사용 불가
     >> Normal quantization + Hybrid 전략으로 방향 전환

2. YOLOv8 기본 ONNX 출력 구조 문제
   - 기본 YOLOv8 ONNX 출력: 하나의 텐서에 boxes + scores + dfl이 섞여 있음
   - RKNN INT8에서: score 채널이 거의 0에 수렴, mAP 급락(0.07 수준)
     >> ONNX 출력 분리 필요: outpuy0_boxes(1x4x8400), output0_scores(1x1x8400)

3. hybrid_quantization_step1 / step2 사용 난이도
   - step1 산출물(*.quantization.cfg, *.model, *.data)이 ~/convert/ 또는 ~/convert/_hybrid_tmp/ 에 저장되는 등 위치가 일관되지 않음
   - quantization.cfg를 YAML로 로드/재저장하면: quantize_parameters.scale 변조, DuplicateKeyError, step2 실패
     >> TEXT ONLY 패치 전략으로 해결
     >> YAML 파싱 X
     >> 문자열 기반으로 custom_quantize_layers 블록만 수정
     >> *.cfg.orig, *.cfg.patched 항상 보존

# 성공 전략

1. Hybrid INT8 + FP16 유지 레이어 선택
   - 다음 레이어를 FP16으로 유지
     >> output0_boxes
        output0_scores

        /model.22/dfl/Softmax_output_0_sw_sw
        /model.22/dfl/Transpose_1_output_0_sw
        /model.22/dfl/Reshape_output_0
        /model.22/dfl/Reshape_1_output_0_rs

        /model.22/Mul_2_output_0-rs
  - DFL(Distribution Focal Loss) 경로 보존
  - 박스 expectation 연산 전확도 유지
  - score 채널 saturation 문제 해결

2. Hybrid INT8 최종 성능(YOLOv8n / Odroid M2 / C++)
   - Avg Inference = 16.22 ms
   - FPS = 61.67 FPS
   - Precision = 0.8048
   - Recall = 0.8047
   - F1 score = 0.8047
   - mAP@50 = 0.7726
     >> FP16 대비 체감 손실 거의 없음
     >> INT8 기준 매우 우수한 결과
     ref) 순수 FP16이 아니라 대부분 INT8 + head/DFL 일부 FP16인 "Hybrid INT8" 결과임

# 확장 진행 상황
- YOLOv8n 성공 후
  >> 동일 파이프라인을 그대로 적용하여 YOLOv8s, m, l.pt 모델 convert_all.py 스크립트로 일괄 변환 시작
- convert_all.py 기능 요약
  >> PT -> ONNX -> ONNX split
  >> Hybrid INT8(step1 -> patch -> step2)
  >> cfg/model/data 위치 자동 탐색
  >> patched cfg 항상 저장
  >> prset(accurate / balanced / aggressive) 지원
